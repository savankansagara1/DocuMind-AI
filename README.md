ğŸ“„ DocuMind AI
==============

**ChatGPT-like PDF & Knowledge Assistant (RAG-Powered)**

DocuMind AI is a full-stack **Retrieval-Augmented Generation (RAG)** application that allows users to **upload PDFs and chat with them intelligently**, while also supporting **general AI conversation** when no document context is provided.

Built with a **production-grade architecture**, DocuMind AI combines modern LLMs, vector search, and a clean chat UI to deliver accurate, context-aware answers.

ğŸš€ Live Demo
------------

*   **Frontend (Vercel):** [https://docu-mind-ai-zeta.vercel.app/](https://docu-mind-ai-zeta.vercel.app/)
    
*   **Backend API (Render):** [https://documind-ai-2.onrender.com](https://documind-ai-2.onrender.com/)
    

âœ¨ Key Features
--------------

### ğŸ“Œ Document-Aware Chat (RAG)

*   Upload any PDF document
    
*   Automatically chunks and indexes content
    
*   Answers questions **strictly from document context**
    

### ğŸ¤– General AI Chat

*   Works like ChatGPT when no PDF is selected
    
*   Intelligent fallback if document context is not relevant
    

### ğŸ§  Contextual Memory

*   Maintains conversation history per session
    
*   Supports natural follow-up questions
    

### âš¡ Scalable Vector Search

*   Uses **Pinecone** for fast semantic similarity search
    
*   Isolates documents using namespaces (multi-PDF ready)
    

### ğŸŒ Modern Web UI

*   ChatGPT-style interface
    
*   PDF upload + chat in one flow
    
*   Clear distinction between **PDF mode** and **General mode**
    

### â˜ï¸ Cloud Deployed

*   Frontend on **Vercel**
    
*   Backend on **Render**
    
*   Designed for real-world production usage
    

ğŸ—ï¸ System Architecture
-----------------------
```
User (Browser)
   â†“
React UI (Vercel)
   â†“
Express API (Bun, Render)
   â†“
LangChain RAG Pipeline
   â†“
Pinecone Vector Database
   â†“
LLM (Groq)
```

ğŸ§  How It Works (High Level)
----------------------------

1.  **PDF Upload**
    
    *   User uploads a PDF
        
    *   Backend saves it temporarily
        
    *   Document is chunked and embedded
        
    *   Vectors are stored in Pinecone under a unique namespace
        
2.  **Chat Flow**
    
    *   User asks a question
        
    *   If a pdfId exists â†’ RAG search is performed
        
    *   Relevant chunks are sent to the LLM
        
    *   If no relevant context is found â†’ fallback to general chat
        
3.  **Conversation Memory**
    
    *   Recent messages are stored per session
        
    *   Enables follow-up questions with context
        

ğŸ› ï¸ Tech Stack
--------------

### Frontend

*   React (Vite)
    
*   JavaScript
    
*   Fetch API
    
*   Deployed on **Vercel**
    

### Backend

*   Bun runtime
    
*   Node.js / Express
    
*   LangChain
    
*   Multer (PDF upload)
    
*   Deployed on **Render**
    

### AI & Data

*   Groq LLM API
    
*   Pinecone Vector Database
    
*   Google Generative AI Embeddings
    
*   LangChain PDF Loader
    

ğŸ“‚ Project Structure
--------------------
```
company-chatbot/
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ chat.route.js
â”‚   â””â”€â”€ upload.route.js
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ chat.service.js
â”‚   â””â”€â”€ pdf.service.js
â”œâ”€â”€ prepare.js
â”œâ”€â”€ server.js
â”œâ”€â”€ uploads/
â””â”€â”€ package.json
```
Frontend is maintained separately in a chat-ui project.

âš™ï¸ Environment Variables
------------------------

### Backend (Render)
```
GROQ_API_KEY=your_api_key
PINECONE_API_KEY=your_api_key
PINECONE_INDEX_NAME=your_index_name
```

### Frontend (Vercel)
```
VITE_BACKEND_URL=https://your-backend-url
```

â–¶ï¸ Running Locally
------------------

### Backend

```
bun install
bun server.js
```

### Frontend
```
npm install
npm run dev
```

ğŸ” Design Decisions & Stability Notes
-------------------------------------

*   Uses **disk-based PDF uploads** (safe on Render)
    
*   Avoids unstable PDF parsing logic
    
*   Relies on LangChainâ€™s proven PDFLoader
    
*   Keeps infrastructure simple and reliable
    
*   Optimized for correctness before optimization
    

ğŸ“ˆ Future Possible Enhancements 
-----------------------------------------

*   User authentication (JWT / OAuth)
    
*   Persistent chat history (Redis / DB)
    
*   Streaming responses (typing effect)
    
*   PDF management dashboard
    
*   Usage analytics & limits
    

ğŸ§‘â€ğŸ’» Author
------------

**Savan Kansagara** GenAI & Full-Stack Developer

*   GitHub: [https://github.com/savankansagara1](https://github.com/savankansagara1)
    
*   LinkedIn: [https://www.linkedin.com/in/savan-kansagara/](https://www.linkedin.com/in/savan-kansagara/)
    
